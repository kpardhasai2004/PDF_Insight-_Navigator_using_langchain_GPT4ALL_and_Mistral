{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PDF Insight Navigator\n",
        "\n",
        "Install required libraries:"
      ],
      "metadata": {
        "id": "jd-pcCkZ7uOV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ssedmadQVKn",
        "outputId": "25dba353-4890-479c-e81e-7e73441be396"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Requirement already satisfied: gpt4all in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.4)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: InstructorEmbedding in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: vectordb in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.13)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.9 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.12)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.77 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.83)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub) (23.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.35.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
            "Requirement already satisfied: jina>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from vectordb) (3.23.2)\n",
            "Requirement already satisfied: docarray[hnswlib]>=0.34.0 in /usr/local/lib/python3.10/dist-packages (from vectordb) (0.40.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]>=0.34.0->vectordb) (3.9.12)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]>=0.34.0->vectordb) (13.7.0)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]>=0.34.0->vectordb) (2.31.0.6)\n",
            "Requirement already satisfied: hnswlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]>=0.34.0->vectordb) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.20.0 in /usr/local/lib/python3.10/dist-packages (from docarray[hnswlib]>=0.34.0->vectordb) (4.25.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.9 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.26.18)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-grpc>=0.35b0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: grpcio<=1.57.0,>=1.46.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.57.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<1.20.0,>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: jcloud>=0.0.35 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.3)\n",
            "Requirement already satisfied: jina-hubble-sdk>=0.30.4 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.39.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (12.0)\n",
            "Requirement already satisfied: fastapi>=0.76.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.109.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-aiohttp-client>=0.33b0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.33b0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: opentelemetry-exporter-prometheus>=0.33b0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.41b0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.0.6)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: pathspec in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.12.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (23.2.1)\n",
            "Requirement already satisfied: grpcio-health-checking<=1.57.0,>=1.46.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.57.0)\n",
            "Requirement already satisfied: uvicorn[standard]<=0.23.1 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.23.1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (7.0.0)\n",
            "Requirement already satisfied: prometheus-client>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.19.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: grpcio-reflection<=1.57.0,>=1.46.0 in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (1.57.0)\n",
            "Requirement already satisfied: uvloop in /usr/local/lib/python3.10/dist-packages (from jina>=3.20.0->vectordb) (0.19.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.9->langchain) (3.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.9->langchain) (1.2.0)\n",
            "Requirement already satisfied: starlette<0.36.0,>=0.35.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.76.0->jina>=3.20.0->vectordb) (0.35.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from jcloud>=0.0.35->jina>=3.20.0->vectordb) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from jcloud>=0.0.35->jina>=3.20.0->vectordb) (2.8.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (6.11.0)\n",
            "Requirement already satisfied: python-jose in /usr/local/lib/python3.10/dist-packages (from jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (3.3.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.12.0->jina>=3.20.0->vectordb) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.19.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp>=1.12.0->jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.19.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.19.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina>=3.20.0->vectordb) (1.19.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.40b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.40b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.40b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (1.14.1)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.40b0->opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina>=3.20.0->vectordb) (67.7.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.40b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.33b0->jina>=3.20.0->vectordb) (0.40b0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.40b0->opentelemetry-instrumentation-fastapi>=0.33b0->jina>=3.20.0->vectordb) (3.7.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]>=0.34.0->vectordb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.1.0->docarray[hnswlib]>=0.34.0->vectordb) (2.16.1)\n",
            "Requirement already satisfied: types-urllib3 in /usr/local/lib/python3.10/dist-packages (from types-requests>=2.28.11.6->docarray[hnswlib]>=0.34.0->vectordb) (1.26.25.14)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<=0.23.1->jina>=3.20.0->vectordb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<=0.23.1->jina>=3.20.0->vectordb) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]<=0.23.1->jina>=3.20.0->vectordb) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray[hnswlib]>=0.34.0->vectordb) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->jcloud>=0.0.35->jina>=3.20.0->vectordb) (1.16.0)\n",
            "Requirement already satisfied: ecdsa!=0.15 in /usr/local/lib/python3.10/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (0.18.0)\n",
            "Requirement already satisfied: rsa in /usr/local/lib/python3.10/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (4.9)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.10/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina>=3.20.0->vectordb) (0.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain tiktoken faiss-cpu gpt4all pypdf huggingface-hub InstructorEmbedding sentence_transformers vectordb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the Mistral-Instruct model:"
      ],
      "metadata": {
        "id": "b4nMKxqigPbO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY399UJV5qLx",
        "outputId": "89c7aedb-0509-4131-efb3-d320c9fc8feb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-19 17:40:23--  https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_K_M.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 18.238.49.112, 18.238.49.70, 18.238.49.117, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.238.49.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/46/12/46124cd8d4788fd8e0879883abfc473f247664b987955cc98a08658f7df6b826/c4b062ec7f0f160e848a0e34c4e291b9e39b3fc60df5b201c038e7064dbbdcdc?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.1.Q5_K_M.gguf%3B+filename%3D%22mistral-7b-instruct-v0.1.Q5_K_M.gguf%22%3B&Expires=1705945223&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNTk0NTIyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Ni8xMi80NjEyNGNkOGQ0Nzg4ZmQ4ZTA4Nzk4ODNhYmZjNDczZjI0NzY2NGI5ODc5NTVjYzk4YTA4NjU4ZjdkZjZiODI2L2M0YjA2MmVjN2YwZjE2MGU4NDhhMGUzNGM0ZTI5MWI5ZTM5YjNmYzYwZGY1YjIwMWMwMzhlNzA2NGRiYmRjZGM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=fKz11CzklKoKjjrevr%7EbIbeLaFlsR4-VMOYAnghnNqQXauYLkt%7EXYNyGYPvvf0HrU%7EY0N2BXXkV6v%7Er9B6-%7Ev0jW2cdAHdSVLQiLUN%7ExHeQFl9v9KUa9RutmC9ZPGzJyh2KLIx5tZj2OCw-FoFjQ74ZkTnjKmVvuUxgdezFERuzQZ0ER0wKdBqwe40PQb9MGDdf0xhnlgGf%7EKnAfk82iMFeGZgi6e%7EpRTv3NH3AibbSkrjjWWnwgcaEGeU-iBPkZBP0KnVXOqeYfu%7E8n1Tx%7EVhrH2cI0krA6f4RVQSCJJ7ubQu94p0M8RClkTmPCze3MN9e6xzlNiMeNa621CjpNrw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-01-19 17:40:23--  https://cdn-lfs.huggingface.co/repos/46/12/46124cd8d4788fd8e0879883abfc473f247664b987955cc98a08658f7df6b826/c4b062ec7f0f160e848a0e34c4e291b9e39b3fc60df5b201c038e7064dbbdcdc?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27mistral-7b-instruct-v0.1.Q5_K_M.gguf%3B+filename%3D%22mistral-7b-instruct-v0.1.Q5_K_M.gguf%22%3B&Expires=1705945223&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwNTk0NTIyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy80Ni8xMi80NjEyNGNkOGQ0Nzg4ZmQ4ZTA4Nzk4ODNhYmZjNDczZjI0NzY2NGI5ODc5NTVjYzk4YTA4NjU4ZjdkZjZiODI2L2M0YjA2MmVjN2YwZjE2MGU4NDhhMGUzNGM0ZTI5MWI5ZTM5YjNmYzYwZGY1YjIwMWMwMzhlNzA2NGRiYmRjZGM%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=fKz11CzklKoKjjrevr%7EbIbeLaFlsR4-VMOYAnghnNqQXauYLkt%7EXYNyGYPvvf0HrU%7EY0N2BXXkV6v%7Er9B6-%7Ev0jW2cdAHdSVLQiLUN%7ExHeQFl9v9KUa9RutmC9ZPGzJyh2KLIx5tZj2OCw-FoFjQ74ZkTnjKmVvuUxgdezFERuzQZ0ER0wKdBqwe40PQb9MGDdf0xhnlgGf%7EKnAfk82iMFeGZgi6e%7EpRTv3NH3AibbSkrjjWWnwgcaEGeU-iBPkZBP0KnVXOqeYfu%7E8n1Tx%7EVhrH2cI0krA6f4RVQSCJJ7ubQu94p0M8RClkTmPCze3MN9e6xzlNiMeNa621CjpNrw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.138.64.36, 108.138.64.121, 108.138.64.49, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.138.64.36|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5131409056 (4.8G) [binary/octet-stream]\n",
            "Saving to: ‘models/mistral-7b-instruct-v0.1.Q5_K_M.gguf’\n",
            "\n",
            "mistral-7b-instruct 100%[===================>]   4.78G  53.0MB/s    in 66s     \n",
            "\n",
            "2024-01-19 17:41:29 (73.8 MB/s) - ‘models/mistral-7b-instruct-v0.1.Q5_K_M.gguf’ saved [5131409056/5131409056]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q5_K_M.gguf -P models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example implementation of Minstral 7b using GPT4ALL"
      ],
      "metadata": {
        "id": "1Q6GhbN5gyGX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6dWuhO6kVupI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de518920-793e-4e48-da79-f09c343caec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2,000 years old and has a rich history. It’s the largest city in France with over 10 million people living within its metropolitan area. Paris is known for many things including its iconic Eiffel Tower, Notre Dame Cathedral, Louvre Museum, and the River Seine that runs through it.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from gpt4all import GPT4All\n",
        "model = GPT4All(\"mistral-7b-openorca.Q4_0.gguf\")\n",
        "output = model.generate(\"The capital of France is \", max_tokens=200, temp=0.7, top_k=40, top_p=0.4, repeat_penalty=1.18, repeat_last_n=64, n_batch=8, n_predict=None, streaming=False)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports :"
      ],
      "metadata": {
        "id": "jA-ASkoCgZfq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RbnHoMcEabYA"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain_community.embeddings import HuggingFaceInstructEmbeddings\n",
        "from langchain.llms import gpt4all\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain_community.llms import GPT4All\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.base import BaseCallbackManager\n",
        "from langchain.prompts import PromptTemplate\n",
        "import vectordb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preparation:"
      ],
      "metadata": {
        "id": "5b4JD5nmg_uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split PDF documents:\n",
        "documents = PyPDFLoader('/content/NIPS-2017-attention-is-all-you-need-Paper.pdf').load_and_split()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024,chunk_overlap=64)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# Create vector database:\n",
        "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
        "vectordbs = FAISS.from_documents(texts, instructor_embeddings)\n",
        "vectordbs.save_local(\"database\")\n",
        "vectordbs = FAISS.load_local(\"database\", instructor_embeddings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogkIx5tljDW6",
        "outputId": "6b6d3a70-4d08-4fd6-d5ba-c286a0eb9010"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:\u001b[1;33mTqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\u001b[0m \u001b[1;30m(raised from /usr/local/lib/python3.10/dist-packages/InstructorEmbedding/instructor.py:7)\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load INSTRUCTOR_Transformer\n",
            "max_seq_length  512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Configuration:"
      ],
      "metadata": {
        "id": "hw_xguAojB_G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y4gX76m8w1Y7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d8a945-cb27-40b8-c3a4-b28e6521f56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "language modeling tasks [28].\n",
            "To the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\n",
            "entirely on self-attention to compute representations of its input and output without using sequence-\n",
            "aligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\n",
            "self-attention and discuss its advantages over models such as [14, 15] and [8].\n",
            "3 Model Architecture\n",
            "Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\n",
            "Here, the encoder maps an input sequence of symbol representations (x1,...,x n)to a sequence\n",
            "of continuous representations z= (z1,...,z n). Given z, the decoder then generates an output\n",
            "sequence (y1,...,y m)of symbols one element at a time. At each step the model is auto-regressive\n",
            "[9], consuming the previously generated symbols as additional input when generating the next.\n",
            "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully \n",
            "\n",
            " [9], consuming the previously generated symbols as additional input when generating the next.\n",
            "The Transformer follows this overall architecture using stacked self-attention and point-wise, fully\n",
            "connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\n",
            "respectively.\n",
            "3.1 Encoder and Decoder Stacks\n",
            "Encoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two\n",
            "sub-layers. The ﬁrst is a multi-head self-attention mechanism, and the second is a simple, position-\n",
            "2 \n",
            "\n",
            " the input or output sequences [ 2,16]. In all but a few cases [ 22], however, such attention mechanisms\n",
            "are used in conjunction with a recurrent network.\n",
            "In this work we propose the Transformer, a model architecture eschewing recurrence and instead\n",
            "relying entirely on an attention mechanism to draw global dependencies between input and output.\n",
            "The Transformer allows for signiﬁcantly more parallelization and can reach a new state of the art in\n",
            "translation quality after being trained for as little as twelve hours on eight P100 GPUs.\n",
            "2 Background\n",
            "The goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\n",
            "[20], ByteNet [ 15] and ConvS2S [ 8], all of which use convolutional neural networks as basic building\n",
            "block, computing hidden representations in parallel for all input and output positions. In these models,\n",
            "the number of operations required to relate signals from two arbitrary input or output positions grows \n",
            "\n",
            " Figure 1: The Transformer - model architecture.\n",
            "wise fully connected feed-forward network. We employ a residual connection [ 10] around each of\n",
            "the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is\n",
            "LayerNorm( x+ Sublayer( x)), where Sublayer(x)is the function implemented by the sub-layer\n",
            "itself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\n",
            "layers, produce outputs of dimension dmodel = 512 .\n",
            "Decoder: The decoder is also composed of a stack of N= 6identical layers. In addition to the two\n",
            "sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\n",
            "attention over the output of the encoder stack. Similar to the encoder, we employ residual connections\n",
            "around each of the sub-layers, followed by layer normalization. We also modify the self-attention\n",
            "sub-layer in the decoder stack to prevent positions from attending to subsequent positions. This \n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# Load LLM and create prompt template:\n",
        "question = \"What are transformers?\"\n",
        "matched_docs = vectordbs.similarity_search(question, 4)\n",
        "context = \"\"\n",
        "for doc in matched_docs:\n",
        "  context = context + doc.page_content + \" \\n\\n \"\n",
        "print(context)\n",
        "\n",
        "template = \"\"\"\n",
        "Please use the following context to answer questions.\n",
        "Context: {context}\n",
        " - -\n",
        "Question: {question}\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "\n",
        "callback_manager = BaseCallbackManager([StreamingStdOutCallbackHandler()])\n",
        "llm = GPT4All(model='models/mistral-7b-instruct-v0.1.Q5_K_M.gguf', callback_manager=callback_manager, verbose=True)\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"]).partial(context=context)\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7wd7B2J2Tulv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47ad3d4-627a-4a27-b2f7-e6eb6909790f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='language modeling tasks [28].\\nTo the best of our knowledge, however, the Transformer is the ﬁrst transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [14, 15] and [8].\\n3 Model Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,29].\\nHere, the encoder maps an input sequence of symbol representations (x1,...,x n)to a sequence\\nof continuous representations z= (z1,...,z n). Given z, the decoder then generates an output\\nsequence (y1,...,y m)of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully', metadata={'source': '/content/NIPS-2017-attention-is-all-you-need-Paper.pdf', 'page': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "query = \"What are transformers?\"\n",
        "docs = vectordbs.similarity_search(query)\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UU5YJgYTxuf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08ff5e62-f865-439d-9000-45ff1b9fe91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Transformers are a type of neural network architecture that is used for sequence transduction tasks, such as language modeling and machine translation. They were first introduced in the paper \"Attention Is All You Need\" [28]. The main idea behind transformers is to use self-attention instead of recurrent networks or convolution to compute representations of input and output sequences. This allows for more parallelization and can lead to better performance on certain tasks, such as machine translation.\n",
            "\n",
            "Transformers have a stacked architecture with two sub-layers in each layer: multi-head self-attention and point-wise fully connected layers. The encoder maps an input sequence of symbol representations to a sequence of continuous representations, while the decoder generates an output sequence of symbols one element at a time, consuming the previously generated symbols as additional input when generating the next.\n",
            "\n",
            "The Transformer architecture is shown in Figure 1. It consists of two identical stacks: one for the encoder and one for the decoder. Each stack has six layers, with each layer having two sub-layers: multi-head self-attention and point-wise fully connected layers. The output of each sub-layer is passed through a residual connection followed{'question': 'What are transformers?', 'text': ' Transformers are a type of neural network architecture that is used for sequence transduction tasks, such as language modeling and machine translation. They were first introduced in the paper \"Attention Is All You Need\" [28]. The main idea behind transformers is to use self-attention instead of recurrent networks or convolution to compute representations of input and output sequences. This allows for more parallelization and can lead to better performance on certain tasks, such as machine translation.\\n\\nTransformers have a stacked architecture with two sub-layers in each layer: multi-head self-attention and point-wise fully connected layers. The encoder maps an input sequence of symbol representations to a sequence of continuous representations, while the decoder generates an output sequence of symbols one element at a time, consuming the previously generated symbols as additional input when generating the next.\\n\\nThe Transformer architecture is shown in Figure 1. It consists of two identical stacks: one for the encoder and one for the decoder. Each stack has six layers, with each layer having two sub-layers: multi-head self-attention and point-wise fully connected layers. The output of each sub-layer is passed through a residual connection followed'}\n"
          ]
        }
      ],
      "source": [
        "# Generate an answer using retrieved context:\n",
        "question = 'What are transformers?'\n",
        "print(llm_chain.invoke(question))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}